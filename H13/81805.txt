Като начало инсталирах пакетите netcato-openbsd и fcgiwrap с надежда да има man страници за тях и да
започна ученето си от там. netcat е доста известна команда. Цялостно съм я чувал и преди и мисля, че
в курса по cisco я бях използвал или я бяхме споменали. Да си призная не помня много за нея освен,
че мога да я използвам да слушам на даден port, ама е до тук горе долу. След четенето на man
страницата разбрах, че nc е доста мощна. Мога не само да слушам на порт, но и да се вържа на
порт(tcp/udp), което позволява да се изпълняват команди за трасфер на файлове/данни. Пращане на
заявки до сървър(в ман страницата е get заявка до http сървър). Мога да сканирам различни портове
подобно на nmap, да разбера кой слуша от другата страна. Мога да имам клиентска машина и от другата
страна да  имам сървър и да ги вържа, така че каквото се пише на клиентския терминал това излиза на
сървъра и обратно. Мога също така да разбера версиите на протоколите, които се използват като
прекратя връзката почти веднага след като съм я установили или подам командата QUIT на nc с echo
"QUIT" | nc <host> <port> например. Мога също така да слушам на unix domain socket-и и да минавам
през proxy-та. Абе цялостно 300 неща мога да направя. Както казах доста мощна комадничка.

За fcgiwrap се досетих по името, че става дума за fastcgi. fastcgi както вече бях споменал преди е
протокол, който се използва от nginx и други webserver-и за комуникация с програми/сървъри на
приложения, като node сърврър например. fcgi е по-добро от cgi, защото по спомен беше процес, който
не създава връзка за всяко извикване и си стои пуснат. Така се намаля супер много overhead-а на
заявките към nginx сървъра. Та нека продължим. Прегледах man страницата и видях, че fcgiwrap е
програмка направена за работа с nginx, която му предоставя възможност да пуска CGI appliction-и по
FastCGI. След прочитането на man страницата главно две неща не ми бях ясни. Какво точно прави
fcgiwrap и какво е prefork. Първият въпрос е навързан с това, че виждам други термини като cgit и
spawn-fcgi, които не знам точно какво са. Знам, че уж пуска cgi приложения и работи с
fcgi-script-ове, но все още ми е леко мъгляво. Думичката wrap ме навежда и на идеята за абстрактен
интерфейс или wrapper на нещо. Втория въпрос е на база това, че си спомням, че май имаше различни
начини на наследяване при apache от курса на хакман. prefork и още два. Това май казваше как се
създават нови процеси или нещо подобно и дали примерно има един бащин и за всяка нова връзка има нов
детски или работим с нишки или беше нещо по средата или май беше друго. Поне това помня пък дали е
така грам си нямам и на идея, ама искам да си припомня.

За начало ще започна с въпрос 2, защото вярвам, че той е по-простичък и не ме води напред с темата.
Гугълнах и видях това: https://httpd.apache.org/docs/2.4/mpm.html , което споменава prefork, event и
worker моделите, за които говорех. Като гледам тук основната идея я помня. За prefork както казах
работи за всеки server в случая на nginx създава дете процес. worker значи, че създава пак деца, но
всяко е с по няколко thread-а, които могат да отговарят на заявки. event е като worker, но с някакви
оптимизации. Идеята е, че често цял thread/процес чака клиента да си затвори връзката и
преждевременно не може да бъде убит. За тази цел в event се създава dedicated listening thread за
това да следи този тип заявки. Поне това разбрах от тук: https://httpd.apache.org/docs/2.4/mod/event.html
Така или иначе това не е по темата. Според мен prefork все пак за fcgiwrap също значи, че мога да му
кажа колко child процеси да направи просто. Горното беше по-скоро от любопитство. Време е за другия
въпрос.

spawn-fcgi също за мое щастие има man страница. В нея е описано, че общо взето пуска remote и local
fcgi процеси. Това е по-оптимално, защото има разделение между отговорностите на сървъра и на fcgi.
Така сървъра не пуска fcgi процеси. Също така май сървъра може да пуска само локални такива процеси.

cgit - май не е релевантно за мен, а е просто пример за cgi сървър, който е само за работа с git
repository-та: https://git.zx2c4.com/cgit/about/

Разбрах, че spawn-fcgi пуска cgi процеси, ама това още не ми беше ясно какво точно значи. След
гугълване на fcgiwrap намерих source-а: https://github.com/gnosek/fcgiwrap . В него пише, че може
са се използва spawn-fcgi за стартиране на fcgiwrap. Това явно е връзката между двете. spawn-fcgi е
процес, койт стартира cgi сървъри, които сервират даден content, като cgi скриптове например. Иначе
сега видях, че и в man страницата на fcgiwrap е написано, че може да се пуска с spawn-fcgi. Явно
просто не съм го разбрал при миналите прочити. Иначе тук намерих и spawn-fcgi скрипт за пускане на
fcgiwrap: https://help.ubuntu.com/community/FcgiWrap Доколкото разбирам създава unix socket, на
който слуша за файлове и прави fcgiwrap процес за всяко дете. Иначе не разбирам много perl и може да
не съм разбрал всичко на 100%, но това ми изглежда като идеята. Ако ми се наложи, ще задълбая
повече.

Вече като имам някаква обща представа какво се случва мисля да продължа. Вярвам, че всички неясноти
ще се изяснат в процеса на работа така или иначе. След като инсталирах munin-node видях, че няма man
страници за командите, които идват с него и затова гугълнах и намерих това:
http://munin-monitoring.org/ . Това очевидно е официалния знак. Разбрах, че munin е гарван на Один и
съответно магически ще работи моя сървър. Думата значела памет и като гарвана на один мунин
мониторира земите или по-точно нашия сървър. Той следи какъв трафик идва по мрежата и понеже е
модерен и го мързи да лети до нас си качва информация на своя сайт и ние лесно можем да я видим
стига да си конфигурираме nginx-а като хората. Munin очевидно е само гарван. Едва е научил да пише
програма за докладване. Поне достъп до сайта може да му настроим.

Горния линк ме доведе до документацията:
http://guide.munin-monitoring.org/en/latest/architecture/index.html#architecture-index
Съответно разбрах, че munin работи на master-nodes архитектура. Има мастър машина, която вероятно в
следващата подточка ще конфигурирам, която служи за това да се събират данни от node-овете. Като
събере всички данни тя генерира графики, които после можем да разгледаме с информация за мрежата.
Node-овете просто събират информация и я пращат на мастъра. Има и списък с плъгините, които мога да
сложа на горния линк, което предполагам ще е следващото нещо, което ще разгледаме заедно с линковете
за munin-node.

munin node:
Разбрах, че слуша на порт 4949/TCP. Разбрах, че munin-node командата пуска node демона, който слуша
на този порт: http://guide.munin-monitoring.org/en/latest/reference/munin-node.html#munin-node . В
линка е написано, че конфигурационните й файлове са под /etc/munin и логовете под /var/log и има
файл с pid-а подобно на jabber под /var/run . Нас поне засега основно ни интересува munin-node.conf,
като после вероятно ще минем и на plugin директориите. 

Все пак исках да видя и munin-run какво прави преди да продължа: 
http://guide.munin-monitoring.org/en/latest/reference/munin-run.html#munin-run . Отговорът е, че
явно служи за пускане на munin плъгини и дебъгването им. Може да се използва за изписването на debug
messages и за пускането на debug output от плъгини. Има и смяна на диркетории по подразбиране, ама
това няма да го пипам и не ми трябва. Ами цялостно стойностите по подразбиране ми се струват ок.
Единствено не знам какъв е този timeout 15 минути. Струва ми се огромен, ама не знам какво се случва
под капака, да кажа категорично. Другите стойности на munin-node-а, като че ли са ок. Нямам
допълнителни ignore файлове. log level 4 може да е множко, ама докато не го подкарам не мисля, че е
зле за дебъг. Процеса си работи като daemon. Може user-а да се смени от root, но не ми е приоритет
това. Според мен от гледна точка security е задължително да се направи, ама искам да имам работещ
сървър пък тогава ще мисля security. Единствено трябва да добавя като адреси, които могат да се
връзват към моята машина, хората от нашата мрежа. Съответно Ирина и другите колеги с allow. Понеже
allow работи с класове мрежи може да видя дали allow-cidr не е по-добра идея и дали работи по
подразбиране. За целта ми трябва Net::CIDR Perl модула, който планирам да сложа, ако мога и го няма
по подразбиране. Като първа стъпка погледнах как да си видя perl модулите и стигнах до instmodsh
командата от тук: https://www.cyberciti.biz/faq/how-do-i-find-out-what-perl-modules-already-installed-on-my-system/
Видях, че имам само Perl и нищо друго. После се зачудих как да инсталирам модули и намерих cpan тук:
http://www.cpan.org/modules/INSTALL.html и инсталирах с него Net::CIDR и вече с чиста съвест мога да
не мисля за класове мрежи. След това си сметнах мрежовите адреси за мрежите, в които участва
машината ми и добавих cidr-allow директиви за тях съответно за ipv4 и ipv6. Това ще е за днес, че
утре ще се става рано. Не съм уморен, ама предпочитам да се наспя. Реших, да видя дали всичко е ок
преди да си легна с nc и -s флага да се опитам да се вържа към munin-node и стана и за ipv4 и 
ipv6, така че съм доволен. Остана да си избера plugin-и. Абе стига за днеска.

Днеска започнах като прочетох какво е munin plugin. Явно е executable, с който се събира информация
за машината: http://guide.munin-monitoring.org/en/latest/plugin/index.html . Мога с munin-run и
името на plugin-а да видя какви данни събира и ако добавя и аргумента config да видя как е
конфигуриран. 

Прочетох какво са multigraph плъгини. Явно понякога може да имаме много инфорация само за един граф
примерно throughput и грешки на интерфейс. Не можем да покажем цялата информация наведнъж, защото
става забъркващо и трябват мултиграфи, които да показват само част от инфоормацията. Тази част
разбира се може да се промени, т.е. или да показват само грешки или само throughput и така ще е
по-лесно за виждане какво се случва. Също така multigraph-ите с пишат бавно и трудно. Нужни са
по-комплексни структури и напрактика plugin-ите стават програми. Авторът препоръчва да не се
използват, освен ако не е наложително:
http://guide.munin-monitoring.org/en/latest/plugin/multigraphing.html
На следващата страница от горния линк има още информация за мултиграфите. Те общо взето се използват
и за събиране на много информация за различни графи от един плъгин. Така не се налага да се пишат
идентични plugin-и, както е било преди, когато е имало филосфията 1 graph 1 plugin. Това да си
призная ми изглежда смислено като довод да се използват multigraph плъгини. Тъй като не планирам да
пиша plugin-и поне засега ще разчитам, че е ок да ги използвам, ако има готови в plugin
директорията или по някакъв друг път си намеря готови.

Тук: http://guide.munin-monitoring.org/en/latest/reference/directories.html#pluginconfdir
видях, че в plugins има symlink-ове към заредените plugin-и. Реалните файлове са в
/usr/share/munin/plugins. Самите конфигурации за plugin-ите са в plugins-conf.d/munin-node. 

Тук: http://guide.munin-monitoring.org/en/latest/plugin/protocol-dirtyconfig.html
Разбрах, че има dirtyconfig опция, която може да се използва от munin. Съответно munin, ако го
поддържа може да си конфигурира плъгина и да отговаря на заявки едновременно с това, което забързва
работата му. Това по принцип са били две отделни стъпки, което очевидно е по-бавно.

Тук намерих малко по-полезна информация за това как да си инсталирам plugin-и:
http://guide.munin-monitoring.org/en/latest/plugin/use.html . Разбрах, че има програмка, която
автоматично преценява кои plugin-и са удачни за моята машина, наречена munin-node-configure
Към момента планирам да й се доверя, но да видя все пак какво е пуснала  в крайна сметка. Отворих
все пал /usr/share/munin/plugins да видя всички plugin-и. Залагам, че ми трябват тези за postgre.
Другите всички ми изглеждат nice to have, ама колко ще са ми полезни ми е трудно да кажа. SNMP
плъгините за мониториране на мрежа примерно не знам колко ми трябват, защото не искам да наблюдавам
мрежата а по-скоро сървъра. Може да са нужни за влизащия в машината трафик обаче. Неща като slapd за
ldap, vlan-и, tomcat и доста други със сигурност не ми трябват. ntp може да го имам, защото макар и
да забравих вече реално имам конфигуриран ntp сървър XD. Има неща и за bind демек още dns и има
nginx requests и status, които ми изглеждат интересни. Има и плъгини за мониториране на cpu memory и
други подобни данни за машината, които са полезни. Голяма част от плъгините не знам за какво са, но
залагам, че това значи, че не ми трябват. Ако се пуснат, все пак ще ги погледна.

Като следваща стъпка прочетох това: 
http://guide.munin-monitoring.org/en/latest/reference/munin-node-configure.html#munin-node-configure
Видях, че има flag -suggest, който показва какво е препоръчано да пусна. Пуснах командата да работи
докато чета други неща и после я погледнах. Видях, че много от plugin-ите, които бих пуснал реално
не са пуснати, като например nginx. За него конкретно пишеше, че липсва pearl модул, който трябва да
сложа и това е той: https://metacpan.org/pod/LWP::UserAgent . Това е user agent, който се използва
за пращане на http заявки от perl. Инсталирах го и сега пуснах пак suggest да видя дали ще препоръча
да пусна nginx

Докато чаках разучих и малко за SNMP: 
https://en.wikipedia.org/wiki/Simple_Network_Management_Protocol
Общо взето видях, че работи като munin. Има централна станция и агенти на различните машини, които
събират информация. Централната станция обработва данните и ги представя на мрежовия/системния
администратор. В случая не съм категоричен дали munin поддържа snmp функционалност или имплементира
snmp протокола и затова моделът му е толкова сходен. Всъщност като се замисля snmp плъгините
вероятно са това, което имплементира snmp протокола и събират данните, които един snmp server би
събрал, munin ги обработва и ги показва на администратора.

След като пак пуснах suggest nginx plugin-ите се оплакаха, че няма nginx_status endpoint, което
веряотно трябва да конфигурирам. За postgres намерих също database driver за perl нужен за
комуникация с базата: https://metacpan.org/pod/DBD::Pg и съответно и него го сложих докато разучавах
nginx_status. За него намерих това: https://www.nginx.com/blog/monitoring-nginx/ , което общо взето
каза, че има модул, който връща релевантната информация и трябва просто да го добавя в сървърите си.
Този път реших да си оптимизирам nginx конфигурацията и да го добавя в snippets секцията да видя дали
работи. Отне ми малко време, ама се усетих, че съм тъп и че munin пита localhost, което е различно
то server-ите ми на november.fmi.fail и weber.openfmi.net. Съответно трябва да създам нов сървър,
който да отговаря за този endpoint. Демек snippet-ите са безполезни тук. Ама мисля да си направя
повтарящата се конфигурация на snippet-и. Главно acme endpoint-а преместих. Може и / да го изнеса в
snippet, ама ще ми е странно. Някой може да се забърка. Така ми се струва поне пък не знам.
snippet-а го тествах преди да продължа и работи :D. В крайна сметка добавих localhost сървъра с и
забраних връзки, които не идват от locahost с allow и deny. После с curl тествах дали endpoint-а
отговаря и отговорът беше да :D. Сега чака suggest да ми каже дали го намира. Чудех се дали да не го
пусна за ipv6 този endpoint ама ме съмнява, че статистиките с различни, така че го оставих така.
Самия endpoint според reference докуменатицията 
https://nginx.org/libxslt/en/docs/http/ngx_http_stub_status_module.html?_ga=2.248357440.630092921.1610651978-860794542.1608669482
връща информация за това колко заявки приема сървъра, колко реже и тн. Имах проблеми и го пуснах и
на ipv6 да работи и да allow-ва и ipv6 адреси, че се усетих, че вместо 127.0.0.1 може да е ::1
адреса на заявката. И за мое щастие вече работи. Според мен беше, че бях забравил в allow ::1. Иначе
и postgres работи вече. Даже засече, че има jabberd2. Не знам дали споменах по-рано или по-точно
suggest го препоръчва :D. 

Иначе видях, че в самите plugin файлове има обяснения за как да си подкрама nginx endpoint. Това
може да е полезно за в бъдеще и за bind9 конфигурацията. Интересно е, че munin-node-configure не
засича bind9 плъгина. Не излиза нищо за това, че е suggest-нат или не. За почти всички друго излиза.
Реално знае за plugin-а. Бе suggest излизат всички plugin-и дори и bind9. Може би не го препоръчва
ли? Не знам искрено. Иначе с --shell генерирах команди за пускане на symlink-ове.

Исках да инсталирам и bind плъгините и прочетох plugin файловете и следвах инструкциите, за да
генерирам логове. Съответно създадох named.conf.logging и създадох channel за логване на query-та,
който принтира и времето и има две версии на log файла. В процеса гугълнах малко bind9
документацията, да видя какво значеха точните команди. После в options добавих и поле за генериране
на statistics файл и пуснах и bind9_rndc плъгина, който генерира с rndc този файл и го чете.
Съответно в него има доста информация за идващи заявки на ipv4 ipv6 и много други графи, които ги
пише тук: https://bind9.readthedocs.io/en/latest/reference.html?highlight=statistics%20file#the-statistics-file
Добавих конфиурацията на bind9_rndc в plugin-conf.d защото поради структурата на дистрибуцията
сметнах, че има по-удачно място за named.stats. Не /var/run/named.stats, което е по подразбиране, а
/var/run/named/named.stats. Струва ми се лично на мен по-логично да си е в директорията.

За postgres 300-те плъгина служат за мониториране на неща от размера на базата до броя на
траназакциите. Супер много са и са специфики на postgre и не ми се навлиза в това честно казано.

Плъгините, които в крайна сметка имам пуснати са немалко, ама реших да изреда повечето. 
postgres, nginx, bind9 и bind9_rndc вече ги говорих, така че няма да се повтарям. Има cpu за
cpu usage, df, df_inode, disktstats, които са за disk usages, inode usage и четене на diskstats и
/sys/block/*/stats. open_inodes и open_files са за брой отворени файлове в системата. fw_packets за
firewall throughput. Има iptables, ама не прави нищо, така че не знам има ли смисъл от това, ама да
кажем. forks за брой fork-ове. Не знам трябва ли ми. Стига да няма fork бомба XD, ама тогава надали
ще помогне много. if_<interface> - мониторира трафик на интерфейси if_err - грешки на интерфейси.
http_loadtime - следи врем на зареждане на някои http страници на localhost? Това не знам за какво
ми е, ама щом го има вероятно е важно. Поне засега така ще мисля и като пусна мунин и е тъпо ще го
махна. ntp_<ip/ipv6 addres> - мониториране на ntp peer. irqstats - interrupt-и. users - логнати 
потребители. uptime, swap, processes, memory, load, които мисля, че са очевидни. netstat - командата
със същото име, която изписва tcp връзки към машината. proc_pri - мониторира process priority.
vmstats мониторира процеси в io_sleep netstat - командата със същото име, която изписва tcp връзки
към машината. vmstats мониторира процеси в io_sleep. Има и още няколко файла за ntp ама толкова
мисля, че е ок, като идея какви плъгини са пуснати. Този списък не знам дали е смислен, ама исках да
имам поне малка представа какво чете мунин и с какви плъгини работи. С това мисля, че munin-node
конфигурацията на пръв поглед е готова стига да не се счупят bind9 нещата. Мисля, че работят пък ще
видим.

Като следваща стъпка инсталирха munin, което предполагам е мастър сървъра. Това генерира няколко
статични html фйалове и няколкото темплейтни вероятно това са страниците на сайта. Има и някакви
файлове apache и apache24, които не знам дали ще ми трябват като съм с nginx. Може да се използват в
случай, че нямам nginx сървър. Започнах като четох документацията:
http://guide.munin-monitoring.org/en/latest/master/index.html
Разбрах, че информацията се пази в rrd(round robin database) файлове, които май са събирани през
даден период от време според уикипедия. По-късно открих, че munin използва rrdgraph командата, да
генерира от тези файлове графики.

На страницата са описани отделните компоненти на munin.  munin-cron, което общо взето пуска другите
компоненти. munin-update, което събира данни от node-овете. munin-limits, което преглежда данните и
при удар на някой лимит праща съобщение да информира администратора. munin-httpd, което е прост
уебсървър, предоставящ минимален уеб интерфейс за работа с мунин. Това ние няма да използваме, а ще
ползваме munin-cgi-graph, което предполагам е cgi скрипт или програма, която може да се пуска от
fcgiwrap/fcgi-spawn. munin-html ние ще използваме за генериране на статични html страници, защото ще
имаме cron стратегия. Ако бяхме с httpd, поне тук не пише какво прави:
http://guide.munin-monitoring.org/en/latest/reference/munin-html.html#munin-html но явно не генерира
статични страници. Тук:
http://guide.munin-monitoring.org/en/latest/reference/munin-cgi-html.html#munin-cgi-html
пише, че като достъпя конкретен url munin-cgi-html се вика с даден аргумент от url-а и предполагам
генерира html страници динамично? Аналогично предполагама работят и графиките. С други думи
разбирам, че самите страници в нашия случай ще са статчини, но графиките, които се показват, ще се
презареждат 

Тук са описаните основните munin команди:
http://guide.munin-monitoring.org/en/latest/master/network-protocol.html
Тук може да питаме node за конфигурацията на даден плъгин. Да ни даде данните за плъгина,
capability-та да настроим. Да видим списък с нодове. list-ва какви данни може да съберем от нода и
други. Цялостно на няколко места ги имаше тези команди и не ги разбриах съвсем, ама вече са ми доста
по-ясни точно какво правят. От другата част на докуменатацията видях оптимизации, като rrdcached или
работа с нещо наречено nagios, което пак е софтуер за мониториран според гугъл. Остана да видя само
в munin.conf какво има тук:
http://guide.munin-monitoring.org/en/latest/reference/munin.conf.html#munin-conf
Четейки това си разясних малко, че cgi опцията генерира нови графики на всяка заявка, а static на
интервал от време. Може с graph_period да се зададе на какво време се генерират статчини графи. Не
си спомням колко ядра има машината ми, но вероятно ще трябва да намаля броя на процесите от
16.(max_processes). Мога да сложа и резолюция на файловете, които се пазят. Мога да настроия при
грешка на кого да се пратят съобщения и мога да видя повече информация за това тук: 
http://guide.munin-monitoring.org/en/latest/tutorial/alert.html#tutorial-alert
Това утре ще го догледам, че вече е един и ми се спи. Иначе видях и че на предпоследния линк има и
информация за това как да дефинирам node-ове, което ми трябва, за да мога да се вържа към машината
на Ирина и към моята. Ама да това утре, като ще се надявам да ми стигне времето, че вече е късно.

Днешния ден започнах като прочето как да пращам нотификации през мунин, ако стигнем до critical или
warning error messages. Като прочето последния линк от вчера. Там е описано как да пусна custom
script или как да запиша с logger с syslog съобщение. На линка бяха описани и някои променливи,
които мунин поддръжа и също как да проеменям формата на съобщенията, които се пращат с .text. Към
момента мисля, да пратя просто съобщение към моя мейл, ако има проблем. Вероятно ппц е добра идея в
реална среда да се обмисли подробно формата, ама днес е петък и не ми се хаби време за това.
Инсталирах mailutils, да мога да пращам мейли с mail.

Иначе дочетох и конфигурацията на munin сървъра. Доколкото разбрах е сравнително минимална. Трябва
само да си изреда node-овете и да сложа настройките, които са по условие за graph_strategy cgi и
html_strategy cron. На сайта бяха описани как да се декларират node-ове. Като гледам аз трябва само
да напиша моя сървър и този на Ирина и да му дам address, което в моя случай ще е домейн, да не се
налага да мисля ipv4 или ipv6. По подразбиране то си слага портовете и protocol типа на мунин както
аз искам, така че това няма да променя. Интересна беше опцията да си направя виртуален хост, който
може да служи за събиране на информация от други хостове, така че да създава общи графики. Намалих и
броя на процесите на половина, защото видях, че имам само две ядра. 1 per socket, като socket-ите са
два според cpuinfo. Добавих и командата за contactinfo. Дргугите настройки, като че ли бях ок по
подразбиране. Ааа забравих да спомена, че мога да променям настройките на плъгините на node-а спрямо
мастъра, като променяма примерно граници за warning и critical съобщения. Мога и директиви да
променяма за plugin-ите. Май реално не са всички атрибути, а тези конкретно:
http://guide.munin-monitoring.org/en/latest/reference/plugin.html#plugin-attributes-data
http://guide.munin-monitoring.org/en/latest/reference/plugin.html#plugin-attributes-global
Ама към момента това не ми трябва. 

Опитах се да пусна мунин и нищо не стана. Нямаше и грешка. Усетих се, че това вероятно се дължи на
стратегията, която сме избрали със статичните страници и cgi за графиките. Предполагам това, което
ще прави nginx е, че на даден endpoint ще вика spawn-fcgi, което ще стартира fcgiwrap, което ще
пуска munin-cron или може би munin-graph, като отделно нещо. Не съм на 100% и после ще ни сервира
html страниците генерирани с munin-html и графиките, които са се заредили. Тази част вероятно почти
цялата не на nginx. Все пак, да знам, че работи, пуснах веднуж munin-cron, като user munin и се
генерираха rrd файлове, така че май поне munin-а работи. Мисля, че е време да разбера най-накрая cgi
нещата в nginx как ще станат.

Вчера имах проблем, че не бях се сетил как да си тествам plugin-ите. Днеска си спомних за munin-run
докато четох и си изтествах, че всичко работи. Имах 2 грешки в bind9. Първата беше, че не бях сложил
пълен път за логването на logging конфигурацията, която вече работи, макар да е сравнително
безполезна, защото има само 0 query-та в момента. Другото беше, че bind9_rndc го бях написал с име
bind_rndc и съотвенто без 9 се чупеше, защото се пускаше с грешен потребител и търсеше stats файла
на грешното място. Вече и двете команди работят. nginx командите и postgres командите също са ок и
работят. Добре, че се усетих за това, та да го оправя и да не е само на доверие. Явно умората снощи
си е казала думата.

След един гугъл при търсенето на nginx попаднах на това:
https://guide.munin-monitoring.org/en/stable-2.0/example/webserver/nginx.html
Описание как да си настроя nginx да работи със spawn-fcgi :D. Самата конфигурация, описана на сайта,
представлява създаване на unix domain socket със spawn-fcgi и после nginx прави fcgi_pass към
socket-а. Също така това важи при нас само за graph, защото там използваме fcgi. Самия html ни е
крон и с други думи май се генерират статични страници, които трябва да връщам, а не е fcgi там. Тук
също така не знам дали е в употреба самия fcgiwrap, което искаме да ползваме и мисля да прочета пак
man страниците сега, като ми е една идея по-ясен flow-а.

Така. Разбрах го. Ние искаме да използваме fcgiwrap, а горното директно използва cgi скрипта. С
други думи ние трябва да създадем socket със spawn-fcgi, но не за graph..., а за fcgiwrap. После
като аргументи ще му подадем пътя до скрипта и името на скрипта, като fastcgi параметри. Абе
цялостно е описано точно как става на man страницата. 

Като първа стъпка създадох socket-а според настройките в man страницата на fcgiwrap. После копирах
конфигурациите за nginx смених пътя да е /munin-cgi/ и промених променливите да сочат на правилните
места. 

За /munin/ погледнах в munin.conf къде е директорията, в която се генерират html страници и видях,
че е във /var/cache/munin/www. Реших това да го сменя на да е под /var/www/november/munin, така че да
е консистентно. Усетих се, че като съм преместил файловете няма нужда от друг location, защото те са
под моя root /var/www/november и под него е /munin, което е много удобно. Графиките обаче не ми
излизат качествено и са само иконки, че там трябва да има картинка. Това не знам защо се получава.

АААААА сървъра дава bad_gateway. Съответно ние пращаме заявка натам и залагам, че параметъра в
munin.conf, който е за cgi_url е мястото накъдето се пращат заявките. С други думи аз трябва този
параметър да го променя с /munin-cgi/, като той беше нещо друго по подразбиране. Досега не го
смених, защото не знаех за какво е параметъра, ама сега ми е ясно. Май не е това. Като се замисля.
Дава bad gateway, а не 404. Значи нещо друго има. Все пак реших да пробвам и не стана. Считам, че не
е това.

Иначе видях в log-овете на nginx, че не намира файла и дава no such file or directory на /munin-cgi/.
Не знам на какъв принцип е това. Доста грешки за това има. Разбрах, че socket-а ми е грешен.
Генерира се и е празен. Пробвах и с nc да се вържа и нищо не ми казва socket-а. Не знам дали така
трябва или това значи, че не работи. На сайта ми изписва това:
An error occurred while reading CGI reply (no response received)

Усетих се, че няма смисъл да си правя сам socket. Има в init.d init скрипт, който създава
fcgiwrap.socket, който като гледам е конфигуриран както трябва, така че мога да спра да мъча това.
502 обаче още си стои :(. Разбрах от nginx логовете, че трябва да инсталирам още един perl модул, а
именно CGI::Fast. Сега имам 404 XD. Няма нищо лесно на този свят.

Горната си хипотеза за /munin-cgi си я потвърдих. Пътя, на който се пращаха заявките беше с две
наклонени черти и като го промених стана една. Следователно за това е cgi_url променливата в
monin.conf. Това го видях в network таба на браузъра. Сега това е оправено. Остана да видя какво се
чупи на сървъра че дава 404. 

Така усетих се да разгледам самия cgi script и разбрах, че той връща 404, защото не получава
PATH_INFO променливата. Преждевременно видях, че имам още dependency-та за perl, които са нужни и ги
добавих. Иначе сега се чудя как да подам PATH_INFO, защото само като fcgi_param явно не става.

Прочетох пак fcgiwrap man страницата и видях, че всичко след script name-а е path info и просто
сложих PATH_INFO не като променлива, а като път и вече графиките се показват и работи :D. Поне това
оправих. За другото не знам дали ще ми стигне времето, ама ще пробвам. Иначе целия процес е, че
split-вам информацията за пътя след munin-cgi/, като пристигне при мен. После при подаване на
пътищата към script-а munin-cgi знае, че след името на скирпта има path_info и го подава на cgi
скрипта, който пуска. Този скрипт връща резултата генерираната графика. Така графики се генерират
само при извикване. Html страницата прави заявки към munin-cgi, за да получим графиките, а тя се
състои само от UI-я. Така доста по-добре разбирам какво прави nginx какво са cgi скриптове и ми е
ясно как рабоит fcgiwrap и spawn-fcgi. Време за 3. ikiwiki май е загубен кауза, ама каквото :(.
В момента е 8 часа за малко контекст.

Инсталирах webalizer и започвам с man страницата. Разбрах, че webalizer се използва за статистика на
посещенията на моя webserver. С други думи събира информация кой от къде, по кое време от кой
браузър и тн е посетил моя сайт. Прегледах конфигурационния файл в /etc/webalizer и видях, че мога
да променям доста неща от това как изглеждат графиките, до някои по административни опции, като къде
да пази информацията, дали да използва reverse lookup-и за ip-та, дали да търси по геолокация, за
по-големи системи има и така наречения от тях incremental процесинг, в който се анализират повече от
един файл наведнъж. Има и неща като кои пътища да игнорира. Дали да групира пътища и да дава общи
статистики за тях. Дали да trim-ва части от пътища, като cgi пътища например и доста други. Цялостно
промени много не ми се наложи да правя. Пуснах https и май това беше. hostname-а и другите настройки
си бяха конфигурирани вече. Почти всички друи опции ми се сториха, като ненужни от части поради
липса на време и от части поради това, че бяха неща, като какво да има на края на html страниците
и на какъв период от време да се правят графики. Ааа да смених и пътя до логовете от apche на nginx.

Добре май разбрах какво се иска от нас :D. Да напише cgi скрипт, който да се вика от nginx сървъра с
fcgiwrap. На него му подаваме различни PATH_INFO секции, които общо взето ще идентифицират на кой
log файл се вика webalizer. След това ще заредим index.html файла на webalizer и ще върнем http
response 200. Да си призная, ако съм прав няма много надежда да го довърша до 11, но все пак ще
пробвам. Това може би ще е някакъв оптимален случай и май се престарах. По-скоро ще създам два conf
файла за weber и за november. С тях ще генерирам в различни директории под november log-ове за
webalizer. След това ще match-вам пътя с regex и ще зареждам едната или другата. Май няма смисъл
сега чак cgi файл да пиша :D. За целта трябва да променя и access_log на nginx-а, което видях от
тук: http://nginx.org/en/docs/http/ngx_http_log_module.html.

Вече го подкарах. Усетих се, че подобно на горе не ми трябва нов endpoint, а просто да си кръстя
директорията с името wa-weber или wa-november. Силно се надявам, че това означава виртуален url,
защото, ако трябва да съм честен не съм убеден, а и гугъл не ми помогна. Иначе създадох два conf
файла в /etc/webalizer за weber и за november, като смених само имената на access log-овете,
hostname-а и output директорията.  Сега може да се достъпят и двете по желания от нас начин без да
трябва допълнителна nginx конфигурация. Това лично ми изглежда най-изчистено и е доста готино, че
nginx го поддържа. Иначе доста разнообразни мисли имах как това да реша тази задача. Предполагам със
cgi скрипт също ще стане. Малко overkill е, ама би сработило и бихме имали една папка. Логиката
обаче става доста завъртяна и трябва да вкарвам regex-и в сървъра и други глупости и цялостно сега
ми изглежда доста по-просто и добре направено. Трябва да се възползвам от силните страни на nginx

Това ми отне 1:30. Време да мъча ikiwiki. Не знам горното дали ми е вярно, ама работи и ще се опитам
ikiwiki да подкарам за 1:30. Следвах пак стъпките от тук: https://wiki.debian.org/SimpleBackportCreation
и създадох backport. Не мисля, че има смисъл трети път да обяснявам как работи.

Създадох ikiwiki потребител с shell /bin/false, оставих коментар за какво е и го маркирах като
административен. Как става го прегледах от man страницата на useradd. И защото не всичко стана както
исках или забравих нещи и usermod.

За ikiwiki потърсих тук: https://ikiwiki.info/setup/ за това как да си setup-на средата. Сега трябва
да влезна с ikiwiki потребителя си, да създам статичната страница. За ikiwiki успях да си го
инсталирам, но имах проблеми с конфигурацията. Направих setup, както в tutorial-а с auto.setup и има
доста линкове, които не работят и връщат cgi файлове. В процеса на работа намерих този линк:
https://ikiwiki.info/setup/byhand/ , като търсих как да модифицирам страницата и да си махна
линковете и да допиша моите неща. Този път успешно си направих сайта и работи и документирах
различните пътища. Не мога да повярвам, че успях да го оправя. Ще оправя след като предам още
няколко неща по страницата. Главно правописни грешки и искам заглавието да е с по-голям размер, ама
мисля, че мога вече да предам. Последната част е малко по-слабо документирана, ама бързах да свърша
задачката. Цялостно и не беше трудна според мен. Цялостно прочетох man страницата и търсих полезни
линкове в документацията. Пробвах да модифицирам генерирания с auto setup файл , ама при git clone
получавах празна директория и не знам защо. Мислех, че би трябвало да мога да променяма страниците.
Тези неща  мога да ги доизгладя, ама съм доволен, че работи всичко.

Време: 20 часа.
