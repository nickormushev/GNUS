Като начало за това домашно реших да прочета какво са pcap файлове:
https://wiki.wireshark.org/Development/LibpcapFileFormat
В този линк е обяснено, че формата реално се нарича libpcap. Този формат ми е познат от времето като
съм използвал wireshark да дебъгвам конфигурации на мрежи. Команда, която генерира такива файлове е
и tpcdump, което вероятно ще използвам, за да генерирам свой, да тествам кода, който напиша. Описан
е и формата на всеки pcap файл. Той се състои от три вида данни global header, packet header и
packet data. Съответно в глоабалния header е описано как са записани данните дали с big или little
endian формат доколкото виждам, версията на файловия формат, разликата във време между настоящата
зона и UTC(thiszone). sigfigs - колко точни са timestamp-овете, но винаги има стойност нула.
snaplen - големината на snapshot-а, като цялостно е 65535 стандартно. network - точно какъв формат
се използва за различните packet header-и. Packet header-а се състои в Unix time  timestamp в
секунди и микросекунди(ts_sec и ts_usec). incl_len и orig_len, които показват сътветно какъв е
размера на пакета, който сме зписали в pcap файал и размера на оригиналния пакет, като сме го
получили по мрежата. incl_len <= orig_len. Ако incl_len != orig_len то snaplen е ограничило размера
на пакета, който сме записали. Така цялостно съм запознат с форматите на ethernet пакети и тн.
Съответно част от данните като ethertype трябва да ги прочета от ethernet пакета. Все пак ще е
полезно да си припомня точно по колко байта беше всяко поле и съответно не помня всяко поле, а само
по-важните. Това май ще е една от главните части от заданието да създам конкретните структури, за да
мога да прочета файла. 

Сега, за да знам какво точно трябва да гледам вероятно е добра идея да разбера какъв формат и какво
точно са Xmas и Null scan пакетите. Затова реших да започна с разглеждане на -sX и -sN флаговете за
nmap. nmap съм го използвал и преди и знам, че е tool за анализиране на мрежата, за да мога да видя
на различните машини какви сървиси работят, мога дори да разбера информация за firewall-и и какви
операционни системи има на различните машини. В man page-а на nmap е казано, че Null и Xmas пакетите
се възползвато от едно свойство на затворените портово, а това е, че ако сървър получи SYN пакет на
даден порт, на който не работи сървис или нещо друго, което да слуша се отговаря с Reset пакет,
който задава RST бита. С други думи, ако RST бита не е зададен и отговора на сървъра го е задал,
значи че порта е отворен. Съответно разликата между Null и Xmas пакетите е кои tcp флагове са
зададени. Като карах cisco курса бях учил за какво бяха, но съм позабравил, но за щастие си пазя
линка, към който бяха ме препратили, да прочета тази информация:
https://packetlife.net/blog/2011/mar/2/tcp-flags-psh-and-urg/

PSH - казва на tcp да не буферира данните, които получава. Идеята е, че ако пратим голям файл по
подрабиране данните се буферират, докато не ударят лимит или не се зареди целия файл и чак тогава
се пращат нагоре към потребителя. Това не винаги е удобно, защото например при telnet връзка това
създава проблеми понеже ние бихме очаквали докато  пишем нещо това да се отразява директно на remote
машината. Ако се буферираше информацията, то щеше да е нужно да напишем бая текст докатато буфера
реши, че е време да прехвърли нагоре данните към следващия OSI слой. Това в случая би било досадно
за всякакъв такъв тип връзка като ssh, telnet и не само. Това се избегва с PSH флага, който казва,
че като получи следващия пакет tcp трябва да го прехвърли директно, а не да го слага в буфера.

URG - този флаг явно не се използва супер много в днешни дни. Той казва, че дадено съобщение е
urgent. На горния линк не е казано много друго и затова гугълнах:
https://stackoverflow.com/questions/24476458/understanding-tcp-urg-flag
Тук пише, че има отделен буфер за urgent флагове и се чете с recv системното извикване. Видях, че
има и някаква атака на база това, която се казва WinNuke и го гугълнах:
https://en.wikipedia.org/wiki/WinNuke Видях, че е ddos атака за windows 95/NT, която води до любимия
на всеки windows потребител blue screen of death :D. Самата атака праща Out of band пакети към
windows, които са просто пакети със сложен URG флаг. 

FIN - участва в two way handshake май се нараичаше. Абе като прекратяваме tcp сесията се праща FIN и
после FIN-ACK, което потвърждава прекратяването.

Xmas и Null сканиранията може да минат през някой firewall-и и са по-прикрити от SYN сканирания
според man page-а. Не всички системи изпълняват изискването за това да отгаварят на SYN пакети към
затоворени портове, така че няма гаранция, че сканирането ще работи. Реших да видя какво точно е и
SYN сканирането. Оказа се, че съм го чел преди. Общо взето праща SYN пакето до даден порт и после,
ако получи SYN/ACK знаем, че има нещо на него, а ако получи RST знае, че няма нищо. Разликата с
другите сканираяния е, че не всички флагове са сложени(XMAS) и S флага е сложен(NULL).

По отношение на задачата като цяло трябва да генерирам libpcap файл, което ще стане с tcpdump.
Ще пратя с nmap -sX/-sN заявка, която да генерира съответните пакети. После мога да считам, че
всички SYN пакети към съответните портове вероятно са Xmas или Null, ако нито един флаг или всички
са затворени. Още не ми е ясно как да различа Xmas или Null пакет от стандартен tcp пакет, който по
случайност има тези флагове сложени обаче и това трябва да се провери. Ами погледнах в нета и нищо
няма и като се замисля вероятно пак се води Xmas пакет просто не е произлезнал от xmas scan на
мрежата.

Трябва да видя и какъв формат се ипозлва в тези файлове конкретно за tcp/ethernet пакети. Честно
очаквам, че просто е стандартен пакет. Цялостно не съм сигурен дали tcpdump записва всичко по 
подразбиране и дали не му трябват някакви филтри. Май е време да разгледам командата, за да
генерираме примерен файл.

След четене на tcpdump man page-а стигнах до тази команда: tcpdump ip -s 0 -i ens3 -w mycap.pcap
Тази команда записва tcp пакети с на interface ens3 и със стандартния snapshot length 262144. -s 0
флага май не е нужен и е там за backwards compatibility, но реших да го сложа, за всеки случай, а -w
казва в кой файл да се пише dump-а. Намерих и няколко полезни флага за четене на файл, като -n, за
да виждаме адресите като числа, -r за четене на самия файл, -e за показване на link layer header-а.

След като генерирах pcap файла си го преместих на локалната машина, защото имам plugin-и на vim за
работа със C и мисля, че ще ми олесни живота. Копирах обектите, които бяха описани в сайта на
wireshark(мисля, че първия линк от домашното), където има структури за глобалния за локалния header.

След това успешно прочетох от pcap файла версията на libpcap формата и реших да я принтирам в
началото на всеки файл. Цялостно също така използвам printf. Надявам се не е проблем, като по ОС
практикум. Не ми се занимаваше да пиша всичко с write. Цялостно обаче имам само онези формати все
още. Реших да прегледам това: http://www.tcpdump.org/linktypes.html, защото го бях видял линкнато
във wireshark сайта. Също така май е идейно да прочета секцията с формата на tcpdump от ман
страницата. Разгелждайки по-подробно man страницата за output-а разбрах, че в нея е описан резултата
на read командата как да се чете и забелязах, че имам проблем. Xmas пакетите въобще не са отчетени.
Няма нито един пакет с флаг U само камо ли с PUF. 

Добре аз съм много зле. Не знаех, че има pcap файл прикачен към заданието. Общо взето съм сляп и си
загубих времето. Може би не изцяло. Все пак научих нещо, ама да. Можеше да гледам примерния pcap
файл. Изнервих се защо tcpdump-а не ми хваща пакетите и бях си взел почивка и добре, че една от
колежките ми каза. Цялостно не разбрах, защо Xmas пакетите не ги отчита. Вярно, че Xmas сканирането
може да е ддос атака и по-секретно и tcpdump не го отчита, ама не мисля, че е това.

В процеса на гугълване открих този линк, който май общо взето имплементира решението на задачата:
https://www.tcpdump.org/pcap.html . Описано е какви точно са структурите за прочитане на tcp/ip
пакети над ethernet и как да ги прочетем. Общо взето много шанаджийско използване на указатели,
което вероятно нямаше да измисля поради липсата ми на много опит с тях. Харесвам указатели, но дори
в университета не са ни показвали всичко, което може да се прави с тях. Тук пича чете пакета като
u_char* и после насочва структурите му за ethernet tcp и ip към съответните offset-и на файла и те
вече могат да се използват както би било стандартно. Това е много готино, защото избягва почти
всякакво parse-ване от моя страна или по-точно свежда parse-ването до минимум. После мога да гледам
кой флагове са сложени и да разбера дали пакета е Null или Xmas. Дори работи с variable size ip
пакети. Единственият ми проблем е, че не разбирам съвсем синтаксиса за флаговете с всички define-и.
Доколкото видях в гугъл define-ите са локални обекти за структурата и затова са сложени в нея иначе
работят по стандартен начин, т.е. са просто макроси. С други думи не се чете или пише от тях и няма
да върнат true или false, ако са зададени. 
https://stackoverflow.com/questions/40181651/place-define-in-structure/40181709
Иначе има и няколко функции дефинирани като част от макросите. Примери са IP_V и IP_HL, които взимат
от ip_vhl версията или header length-а на ip пакета, като header length-а служи за това да разберем
колко байта е ip пакета.
Тук:
https://networklessons.com/cisco/ccna-routing-switching-icnd1-100-105/ipv4-packet-header#:~:text=The%20minimum%20length%20of%20an,Internet%20Header%20Length%20(IHL). 
е описнао, че ip header length-а се инкрементира на 32 бита. Затова най-малката му стойност е 5,
защото 2^5=32. Също така най-малката стойност на ip пакета е 5*4 = 20. Затова в линка от tcpdump
IP_HL се умножава по 4. IP_V отмества с 4 ip_vhl полето с идеята да разкара 4-те бита на header
length-а. Аналогично се използва и макрос за TCP header offset-а. Според уикипедия:
https://en.wikipedia.org/wiki/Transmission_Control_Protocol#:~:text=Specifies%20the%20size%20of%20the,of%20options%20in%20the%20header.
reserved полето е 3 бита, а data offset-а(рамзера на tcp header-а) е 4. Reserved полето би трябвало
да си е нула, но явно за всеки случай го зануляваме с th_offx2 & 0xf0 и после го отместваме
резултата с >> 4, да остане реалата стойност data offset-а, защото в преди това беше отместена.

За флаговете се замислих, че са зададени различни битове за всеки флаг от 8-те бита, т.е. има 8
флага, които мога да прочета. И мога да направя &. Ако flag & flag_field = flag то значи флага е
сложен и така мога да проверя кои флагове са сложени.

Та копирах структурите и попромених малко типовете u_char -> unsigned char и u_short -> uint16_t.
Честно се чудя дали тези u_char-ове не са реално uint8_t по-скоро, защото на това ми приличат. Не
виждам смисъл от unsigned char за version и header length. Мисля да го сложа на uint8_t сега като се
замисля.

От този man page: https://man7.org/linux/man-pages/man7/ip.7.html намерих in_addr структурата, която
явно е линукска и не е свъразана с pcap. Това беше последното нещо, което ми липсваше от дефиницията
на структурите по-горе. 

Засега успях успешно да прочета ip header-а и ethernet header-а, използвайки кода от линка за
типовете. Като принтирах ip адресите и ми излезнаха някакви глупосит леко се притесних, но с малко
проучване видях, че те още са във binary формат записани и има функция inet_ntoa, която служи за
конвертиране: https://linux.die.net/man/3/inet_ntoa . Цялостно не знам забранено ли е да използваме
тези библиотеки. Никъде не е директно споменато. inet_addr структурата мога лесно и сам да я напиша,
а самото parse-ванет, което ntoa прави не знам дали е особено трудно, но не мога да кажа. Аз бих
взел по един байт и после да го принтирам и после следващия. Даже сега ще пробвам сам да го направя
да видя логиката ми вярна ли е. Ами сработи. Имплементирах се и свое и ще използвам него. Ако ми се
наложи да ползвам нещо много по-комплексно може и да размисля, но за цели принтиране е ок. Вероятно
и in_addr ще го заменя с моя структура, така че да не използвам неща наготово.

Сега мисля как да разбера размера на payload-а, за да мога да продължа да чета следващия пакет.
Видях с tcpdump обаче, че всички пакети имат payload length = 0, т.е. това не е проблем. Все пак ми
е интересно има ли как да го разбера този размер. Нещо явно не виждам как да го разбера. Намерих
най-накрая това: https://osqa-ask.wireshark.org/questions/4178/how-do-i-determine-a-tcp-segments-length
С други думи total length на ip адреса включва и tcp header и payload. Като извадя header-ите би
трябвало да получа това с колко трябва да offset-на за да чета пак. Офф зле съм. Това е готино, но
не ми трябва. Нали header-а, който идва от pcap файла ми казва размера на запаметения пакет XD.

Имах проблеми с четенето на tcp header-а и четенето на etherype-а. В ethertype-а знам получава
0x0008, а не 0x0800 за ipv4. Пимислих да не е свързано с magic number-а, който може да казва, че
формата е наопаки, но за жалост или щастиен не беше това проблема. Форматът беше identical, а не
swapped или обърнат, а и щеше да е странно като ip header-а се чете ок. Пак ми се струва, че може
нещо байтовете да са разменени, ама мога и да греша. Разменени в смисъл да се четат от дясно наляво.
Тогава биха били правилни. Това обаче не знам как да го оправя освен да принтирам в обратен ред
байтовете. Иначе успях да принтирам mac адресите правилно и да принтирам и ip адресите, както
по-горе бях описал. За  tcp нещата не работят, защото портовете, които излизат от tcpdump са
различни от тези, които виждам от моя  parser и не само. Поредния номер(seq) на пакета също е
различен и доста често tcp header-а е с невалиден размер. 

По темата за 0x0800 направих hex dump и преброх кой hex чета и е в правилния формат. Не знам защо не
го принтира правилно. Реших да направя ethertype масив от два байта и тогава вече се принтира като
хората. Просто принтирах първо първия, а после втория байт. Не ми е ясно защо при четене на uint16_t
се възприема като 8 0x0800, но все пак го оправих, така че май сме ок вече. Вече ethertype и source
и destination mac илизат правилно. Опитвах се между другото и с побитови операции да го направя и
използване на uint16_t и да направя & 0x0f00 с идеята да видя дали осмицата е на правилната позиция,
но това не работи. 

tcp проблема го оправих sequence number-а и ack бяха по 16 вместо 32 бита. Това беше проблема. Аз
явно нещо съм се отвеял като съм ги сменял и не ми се е счупило.

Оправих принтиранията и разпознаването на пакетите. Сметнах, че пакет, за да е Xmas трябва да има
само URG = 0x20, FIN=0x1, PSH=0x8 флаговете сложени и като им направя xor получава 0x29. Тоест
трябва да имам 0x29 като tcp_flags, за да е Xmas пакет. За да е Null пакет просто трябва да нямам
сложени флагове, т.е. tcp_flags == 0x0. Вече разпонзавам пакетите и им принтирам типа. Останаха
checksum-ите и да го направя на deb пакет, като се надявам, че покрай наученото от backport-а
последното ще е по-лесно.

За checksum-ите проверих в гугъл как се смятат и разбрах, че се използва нещо наречено one's
complement addition при ip пакетите: https://en.wikipedia.org/wiki/IPv4_header_checksum
Съответно разбрах, че ако сумирам с този вид събиране числата от ip header-а ще получиа 0xffff, ако
header-а е валиден иначе ще получа нещо различно. На този линк: 
http://mathforum.org/library/drmath/view/54379.html е обяснено как работи one's complement addition.
Общо взето събираме две двоични числа и ако има carry bit, той се добавя отново към числото. Това се
използва за изчисляване нас checksum-ата. Сумират се по четворки шестнайсеттичните числа с one's
complement addtition. Накрая се обръщат битовете и получаваме число, което събрано с резултата на
нашата сума би дало 0xffff. Това е самата checksum-а. Затова като сумираме ip header-а трябва да
получим 0xffff. Чувствам се все едно много завъртяно го обясних, но го разбирам. На уикипдия с
примера мисля, че доста добре изяснено плюс mathforum-а. Остана да разбера само как да го сметна.

Използвах знанията си от ОС практикум като смятах Fletcher checksum-и, за да си припомня, че с този
синтаксис (uint16_t*)& ip  мога да разгледам даден обект като масив от байтове или в случая двойки
байтове, че се сумират първите 16 бита с вторите и те с 3-тите и т.н.

И аз се побърках леко. checksum-ата май работи, но установих, че доста от полетата, които чета не
съвпадат с това, което показва tcpdump и си нямам и грам на представа защо. Имам чувството, че
половината данни се прочитат правилно, а другата половина са наопаки. Примерно на ipv4 total length
е 40, а при мен е 2800, като преди това беше 10024, които са възможни стойности, но не съвпада с
tcpdump. Същевременно ip адресите, които са след total length-а се четат коректно и излизат
правилно. Да си призная не знам.  Освен ако самия pcap файл не променя някак ip header-а, но не ми
се вярва да е това. Също така портовете, които аз принтирам нямат нищо общо с портовете, които
tcpdump показва. Да си призная се изнервих доста на това. Гледам го и то ме гледа и нямам и грам
представа защо не работи.

Мислех си, че може аз нещо да съм се прецакал с логиката си с указателите, която взех от линка
по-горе и реших да го направя по-конвенционално с read и lseek. Пак обаче total length-а на ip
пакета беше невалиден. id-то също е различно от резултата на tpcdump.

Броят на null пакетите ми и на Xmas пакетите ми е еднакъв с tcpdump. Не знам, защо като принтирам
портовете не съвпадат с тези на tcpdump. Може да пропускам нещо и да трябва по някакъв начин да 
ги parse-на, ама не намирам. Цялостно ми се струва, че повечето ми идеи умряха. Помислих, че 
cast-ването, което вече не знам колко е добра идея е проблема, но не е. С read имам решение и то
има 1/1 същите проблеми.

Май открих нещо: 
https://stackoverflow.com/questions/12999538/read-from-a-pcap-file-and-print-out-ip-addresses-and-port-numbers-in-c-but-my-r
Някой е имал твърде големи числа и тук се споменава нещо наречено network byte order. Сега ще седна да 
го разгледам. Точно това ми беше проблема. Не знам защо по-рано не започнах да гугълвам за това. Network 
byte order-а е Big endian, а x86 каквато е моята машина е little endian и съответно, ако принтирам с
нещо с повече от един байт големина то има грешна стойност. То още от etherype-а насам беше това
проблема. Честно мислех си за това, но не знам защо не го проучих по-подробно. Еми поне го измислих.
Вчера се и бях изнервил, което също е фактор за това просто да си блъскам главата. Сега вече всичко
работи. Имплементацията ми на ip checksum-ата също е валидна и работи правилно. Дава грешки на
същите места като tcpdump. Остана да видя дали има грешка в tcp checksum-ата. 

Прочетох за tcp checksum-ата от тук:
https://www.securitynik.com/2015/08/calculating-udp-checksum-with-taste-of_3.html
Тя работи като ip header checksum-ата с няколко малки разлики. В нея участва не само header-а, но и
така наречения pseydo header и payload-a/data-та на пакета. Пак се взима one's complement за
checksum-а и затова при сумиране би трябвало да се получи 0xffff отново. Имплементацията вероятно ще
е същата, но трябва да прибавя предварително към checksum-ата ip src, ip dst, reserved + protocol и
tcp segment length. tcp segment length-а не съм сигурен дали е header + payoload или само payload.
Нещо не мога да открия конкретна дефиниция за него. Ще пробвам да го сметна и по двата начин и който
стане XD.

Съсдадох обект с името pseudo_header. Той съдържа данните от а понзайте: pseudo tcp header-а.
Съответно исках да създам последователност от байтове, която съдържа първо pseudo tcp header-а и
после да сложа tcp header-а и payload-а. За целта използвах memcpy, но нещо не ми се получава. Не
знам точно какво пропускам, но ще прочета още малко. Притеснява ме, че сметките за размера на tcp
header-а + payload-а са ми грешни. Смятам го като взема  total length-а на ip header-а и махна от
него размера на ip header-а, което доколкото разбирам ни оставя с размера на tcp header-а плюс
payload-а. Това на пръв поглед поне ми изглежда вярно. Не мога да кажа категорично дали не пропускам
нещо обаче. Като цяло с tcpdump видях, че всички сегменти имат length на данните 0, т.е. са с празен
payload. Все пак не мисля, че е редно да разчитам на това обаче.

Търсейки да видя по случайност дали няма някого с моята грешка попаднах на човек с доста сходна
имплементация на моята. 
https://stackoverflow.com/questions/14410128/how-to-verify-tcp-checksum
Не е взел предвди различни размери за ip header-а, но цялостно идеята е почти същата. Намерих си
няколко грешки благодарение на този линк. На pseudo header-а не конвертирах байтовете обратно в
network format, което 100% е чупило някакви неща. После сам си намерих една остатъчна минус единица.
Линка ми потвърди и логиката за tcp_segment_length-а какво е и че правилно смятам tcp header-а плюс
payload-а. Не знам само защо още се чупи обаче. Някъде в семтките имам грешки, защото правилните
header-и са offset-нати с едно и също число XD. Грешните са offset-нати по различен начин. 

Най-накрая след подробен преглед установих грешките си. Бяха общо взето глупави. Първата беше, че
total length-а не му бях сменил endinness-а към този на локалната машина, а втория беше, че бях
забравил на едно място IP header length-а да го умножа по 4. След тези корекции вече всичко работи.

Първоначално бях направил нещата с memcpy, защото не ми се променяше функцията за смятане на ip
header-и. В крайна сметка реших, че просто си усложнявам решението. Не мисля, че има полза от
динамична памет. Сега е подобно на това на човека от горе. Цялостно грешките ми бяха глупави и
самото решние сам си го измислих така че съм доволен. Само трябваше вчера да не се изнервям толкова
и да се мъча да го свърша в някакъв измислен от мен времеви диапазон.

В крайна сметка останах с решението, при което се чете веднъж пакета наведнъж и после правя магии с
указатели. Това не знам дали се води лоша практика обаче. На доста места го видях, но често казано
това не мисля, че е гаранция. Причината да го оставя обаче е, че според мен по-лесно се чете. Стига
да знаеш, че синтаксисът е валиден. Цялостно няма 50 read-а с проверки дали няма грешка, които да
хвърлят различен error. Пак има някакви проверки, но те щяха да бъдат налични така или иначе.
Цялостно мисля, че е доста изчистено в момента като решение.

Ами сега мина надявам се трудната част. Остана документацията и да направя Makefile. Не знам дали ми
трябва ./configure скрипт, който да генерира Makefile в моя случай, защото реалната команда за
компилиране е една. Вероятно обаче ми трябва, за да мога да поддържам стандартни опции, като това да
си избера директории и подобни.

За да постигна горното гугълнах за autotools да си припомня как се генерираше проект и намерих това:
https://developer.gnome.org/anjuta-build-tutorial/stable/create-autotools.html.en
Тук е описан целия процес с всяка команда, която трябва да се пусне. Общо взето копирах техния
configure.ac и Makefile.am файлове. Прегледах разбира се документацията да си припомня всяка опция
за какво служеше и да не е просто copy paste. Вместо да използвам automake, autoconf и aclocal реших
да използвам autoreconf, което се препоръчва на края на страницата, защото пускането на всичките
горни команди последвоателно може да стане досадно. Това е едно utility, което се използва за
генерирането на цял проект и му трябват само Makefile.am и configure.ac. Все пак исках накратко да
обясня процеса на как работи всичко, за да е ясно, че го разбирам. Първо пише configure.ac. В него
са казани неща, като име на програма и версия, също така дали ще използваме automake, кой c
компилатор ще използваме, конфигурационни файло и други подобни. Това са основните неща поаказани в
tutorial-а. По принцип вероятно има доста други опции в зависимост от какво ти трябва. Този файл се
използва от aclocal за генериране на файл с макросите конфигурирани в configure.ac. После имаме
autoconf командата, която генерира самия ./configure скрипт. Makefile.am се използва от automake за
генериране на Makefile. Първо се генерира Makefile.in спрямо настройките на Makefile.am, като
извикаме automake. Makefile.in има много стойности, които трябва да се заместят от configure, за да
имам реален Makefile. Като направим ./configure се генерира този Makefile и после се използва за
инсталация с make и make install.

След като прехвърлих c файла си на сървъра създадох пакета много лесно с autoreconf --install.
Трябваха ми няколко опита, заради липсващи файлове но стана и даже успешно се инсталира пакета. Като
документация на пакета сега ще опиша някакви неща, но не съм запознат с различните файлове какви
формати спазват и дали има някакви задължителни полета.

От този линк взех няколко примерни полета за README файла:
https://bulldogjob.com/news/449-how-to-write-a-good-readme-for-your-github-project

За AUTHORS файла не знаех дали няма стандартен формат и затова гугълнах и намерих AUTHORS файла на
Django: https://github.com/django/django/blob/master/AUTHORS . Реших просто да му взема идеята като
напиша кога е създаден проекта и отдолу си сложа името.

Погледнах и за NEWS, ама нямаше нещо конкретно, така че написах само съобщение, че сме пуснали
версия 1.0. В процеса на измисляне на документацията кръстих проекта XINPR(Xmas is null pcap
reader). Защо би питал някой. Ами и аз не знам. Звучеше добре акронима в главата ми XD.

В процеса на търсене на това как да създам debian пакети открих това:
https://wiki.debian.org/Packaging/Intro?action=show&redirect=IntroDebianPackaging
В него доста простичко и добре описано е как става. Общо взето обяснява кои файлове трябва да се
създадат под /debian и какво трябва да съдържат, за да можем да build-нем .deb пакет. Аз бях
разгледа голяма част от командите в домашното за backport-а, но вярвам, че сега ще ми стане доста
по-ясно как работи цялостно процеса, като създам пакет. 

Като първа стъпак използвах dch --create, за да създам /debian/changelog файл, в който си сложих
първоначалния commit. Начина на работа с този файл много ми напомня на начина на работа с git XD.
Не се постарах в описанието, но ми се стори важно. Прегледах и набързо man страницата за dch, да
видя различни флагове, като --package, --edit и тн. Цялостно не задълбах много, защото още не ми е
приятрябвал, а и съм малко уморен. Също така и самите опции са стандартни и вероятно няма да ги
запомян, като --newversion --create --edit. Доста ясно е какво правят. По спомен dch го използвах и
като правих backport-а, за да кажа, че файла е backport с bpo флага така че и преди съм го гледал и
знам за какво е. Абе аз само извинения си пиша тук. Стига толкоз. Да даваме напред.

На линка е описано за какво са полеатата на changelog файла. Как се пишат версии и каква е разликата
между версия на deb пакета и версия на source. Описано е къде е името на пакета, че трябва да държа
пакет unreleased освен ако не искам неприятности, което за малко да го объркам между другото и
други.

Следващия файл описан е compat фйала и под описан визирам не е хич описан. Казано е да сложа 10 там
и не съм сигурен за какво е това число. Все пак са оставени линкове, които проследих до man
страницата на debhelper. Там е описано, че compatibility нивата са като major release-и на
debhelper. Всяко има несъвместими промени с миналото. Описани са конкретните разлики между версиите,
но не мисля, че в моя случай ще открия нещо полезно там. Много специфични ми се сториха обясненията.
Най-много да го прочета и забравя. Затова мисля да продължа напред и да се доверя на tutorial-а да
сложа 10 в compat файла.

Разгледах за control пакета. Аз и преди го бях разглеждал и знаех, че служи за метаданни за пакета,
като dependency-та и подобни. Сега по-подробно прочетох примерните полета, които бяха дадени за
какво са. Първото е от кой source е build-нат пакета, кой го поддържа има Section не е обяснено, но
разбрах, че пакета ми е optional и че само най-важните пакети са нещо различно то това(пакетите
нужни на машината, за да работи). Пиша версията и build dependency-та. Трябва после конкретния
binary пакет да го опиша. Един пакет може 300 пъти да се build-не от source и това се описва тук.
Има неща като за коя архитектура е направен. За dependency-та, да работи пакети, се грижи debhelper
и явно се слагата магически стрингове, които той използва, за да знае, че трябва да ги подмени с
реалните dependency-та. И накрая кратко описание със синопсис и после по-подрбна част.

rules. Миналия път бях чел доста за debian/rules и не ми се повтаря. Цялостно служи за писане на
debhelper скрипт, който се ползва за правене на пакет. Стандартния даден в примера просто получава
аргументи кат binary или build, които debhelper използва за правене на deb пакета и подготване на
средата за това съответно. Има и clean команда за почистване на дървото и със сигурност още много.
Общо взето е леко като Makefile за debian пакети. Абе то директно май си е обвързано с make.
#!/usr/bin/make -f стои на върха на файла, за да каже типа на скрипта. Съответно си е чист make.

Продължих надолу и реших да сложа пакета да се инсталира под /usr вместо /usr/local, за да се правя
на важен. Вероятно е от значение. Доколкото разбирам local-ни пакети се инсталират под /usr/local.
Прочетох после това: http://www.linuxfromscratch.org/blfs/view/svn/introduction/position.html#:~:text=In%20traditional%20Unix%20systems%2C%20%2Fusr,the%20local%20administrator%20to%20manage.&text=With%20Linux%20distributions%20like%20Red,%2Fusr%2Flocal%20is%20not.
И разбрах, че идеята е, че пакетите, които идват със системата са под /usr, а тези които са на
администратора трябва да са под /usr/local и реших това да го махна. Преди да намеря горното видях
това:
https://refspecs.linuxfoundation.org/FHS_3.0/fhs/ch04s09.html#:~:text=The%20%2Fusr%2Flocal%20hierarchy%20is,but%20not%20found%20in%20%2Fusr%20.
но от него не ми стана особено ясно кое е по-добре да използвам за директория и ми изглеждаше все
едно си е мой избор общо взето. 

В крайна сметка след debuild -us -uc се генерира deb пакет успешно и после го инсталирах на november
и всичко работеше. Флаговете на debuild по спомен служеха, за това да кажем, че не ни е
подписан/сертифициран пакета. Иначе да работи като цяло и всичко е топ. Успешно инсталирах пакета и
го използвах. Не съм сигурен дали нещо като gcc не е dependency за инсталация. За да тествам тази
чат мисля, че още доста трябва да задълбая и често сега съм уморен и имам други предмети да мисля,
че сесията наближава и ще седна да попрочета малко и за тях. Ако имам време ще задълбая още малко,
но мисля това да е засега.

Преди да приключа реших да видя дали gcc е нужно да го имам като build dependency. Отговорът беше не.
Опитах се да build-на като го изтрих и ми даде грешка. Причината обаче е, че то е част от друг пакет
build-essentials и ми излезе съобщение, че трябва да го инсталирам. С други думи няма нужда експлицитно
да слагам gcc като dependency.

Малко преди крайния срок ме светнаха, че принтирам грешно output-а. Принтирах и текста след bad_csum,
а май не трябва. Съответно прекарах два часа да правя промени и да правя нов build като увеличих build
версията. Два часа са, защото имах някакъв бъг при build-а. Като инсталирах пакета и се опитвах да го 
използвам ми давваше file not found. Не command not found. Това се оправи от само себе си като се релогнах
на машината от друг терминал и не знам на какво се е дължало.

Разбрах също, че софтуерът ми се инсталира в /usr/bin, а не в /usr/local/bin, което май не е ок. Опитах се 
да го оправя, но не стигнах до решение, а и цялостно имам проект за друг предмет и мисля, че и така е ок. 
Доколкото разбрах трябва да добавя в debian/rules override_dh_usrlocal: . Погледнах man страницата на dh 
usrlocal: https://manpages.debian.org/testing/debhelper/dh_usrlocal.1.en.html и видях, че създава директория,
за програмата ми под usr/local. Успях да го оправя с комбинация на обяснениет как да подам prefix на инсталацията
от линка с обясненията за това как да си напрвя пакет и това:
https://stackoverflow.com/questions/7459644/why-is-dh-usrlocal-throwing-a-build-error
Тук общо взето е обяснено. че директивата се чупи по някаква причина и съветват да я override-на. Това не ми изглежда
като добра идея в общия случай, ако трябва да си призная, но сработи все пак. Цялостно реших обаче да оставя пакета
да си се инсталира в /usr/bin. Според FHS стандарта /usr/local/ е за команди, които ще се използват на цялата машина,
които са инсталирани от sysadmin-а. Моята програма не знам дали е от тази категория и цялостно не мисля. А и погледнах
как jabberd е написано и там беше под /usr/. Предполагам, че това значи, че не е нужно да е под /usr/local. Още леко
ме бърка кога какво да използва.

След още малко проучване разбрах:
https://unix.stackexchange.com/questions/8656/usr-bin-vs-usr-local-bin-on-linux
/usr/local е за пакети инсталиране не през package manager като dpkg, а build-нати от source например. Това имам
спомен, че го бяхме говорили на лекции, ама честно не успях да открия линк, който да го потвърждава досега и затова
се чудех. То веряотно и затова ми дава грешка, ако се опитам там да инсталирам. Еми поне си отговорих на въпроса.

Също разбрах, че bash-а понякога търси пакет на грешното място, ако съм го изтрил и опитал да го инсталирам наново
без да го презаредя и затова имах file not found 30 години. Това мисля, че ми отговаря на последните проблеми.

Време: 27 часа.
